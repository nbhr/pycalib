{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93f6ee11",
   "metadata": {},
   "source": [
    "# Mirror-based Extrinsic Camera Calibration\n",
    "\n",
    "## Goal\n",
    "\n",
    "The goal of this notebook is to calibrate the extrinsic parameter of a camera w.r.t. a reference object (e.g., chessboard) that is not directly visible from the camera.  The key idea is to capture the reference object through a mirror.  As described in the papers below, we can calibrate the camera and the mirror poses w.r.t. the reference object using 3 or more images taken with different mirror poses.\n",
    "\n",
    "- [Kosuke Takahashi, Shohei Nobuhara, and Takashi Matsuyama, “Mirror-based Camera Pose Estimation Using an Orthogonality Constraint,” IPSJ Transactions on Computer Vision and Applications, vol. 8, pp. 11–19, Feb. 2016.](https://github.com/computer-vision/takahashi2012cvpr)\n",
    "- [Kosuke Takahashi, Shohei Nobuhara, and Takashi Matsuyama, “A new mirror-based extrinsic camera calibration using an orthogonality constraint,” in Proc. of IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2012, pp. 1051–1058.](https://github.com/computer-vision/takahashi2012cvpr)\n",
    "\n",
    "This technique can be used for calibrating a webcam-display system, non-overlapping cameras, and so forth.\n",
    "\n",
    "## Outline\n",
    "\n",
    "Consider a static 3D reference object with $N_p$ feature points ${p'}^{i} \\; (i=1,\\dots,N_p)$ in the scene, such as a chess patten shown in a flat display.  By observing the 3D reference object through a planar mirror $\\pi_j \\; (j=1,\\dots,N_m)$ at $N_m$ different poses, the 3D reference object is mirrored as $p_j^i$ and is projected to $q_j^i$ in the camera image.\n",
    "\n",
    "Given the 3D coordinates of $N_p$ feature points ${p'}^{i}$ in the model (= world) coordinate system and their projections $q_j^i$ in the $N_m$ images, we can calibrate\n",
    "\n",
    "- the 3D pose $R$, $t$ of the camera, and\n",
    "- the 3D normal $n_j$ and the distance $d_j$ of each mirror,\n",
    "\n",
    "in the model coordinate system, i.e., w.r.t. the reference object.  In this calibration, the following assumptions should be met.\n",
    "\n",
    "- The intrinsic parameter $K$ is given a priori.\n",
    "- The 2D positions $p_j^i$ are given in the undistorted image coordinate.\n",
    "- $N_p \\ge 3$ (larger is better)\n",
    "- $N_m \\ge 3$ (larger is better)\n",
    "- The mirror does not have a transparent layer on it, i.e., it is a [first-surface mirror](https://en.wikipedia.org/wiki/First-surface_mirror) without refraction.\n",
    "- The mirror poses are _mutually independent_.  They are not parallel and do not intersect at a single axis.\n",
    "\n",
    "In practice, it is strongly recommended to use a ChAruCo pattern as the reference object since we can easilly identify if the pattern is flipped (mirrored) or not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fb6c09",
   "metadata": {},
   "source": [
    "## Procedure\n",
    "\n",
    "A typical procedure is as follows.\n",
    "\n",
    "1. Prepare images as `INPUT_FILES`.\n",
    "   1. Show a ChAruCo pattern on a flat panel display.\n",
    "      - The following cell generates a pattern image of `DISPLAY_WIDTH` by `DISPLAY_HEIGHT` px and saves it as `OUT_PATTERN`.  Modify these parameters according to your display, and show it in the fullscreen mode.\n",
    "   2. Capture the ChAruCo pattern through a front-surface mirror.\n",
    "      - Capture at least with 3 different mirror poses (change the orientation of the mirror as well as its position **as much as possible**).\n",
    "      - Save them as `INPUT_FILES`.\n",
    "2. Update the intrinsic parameter `cameraMatrix`.\n",
    "   - The intrinsic parameter should be calibrated beforehand.\n",
    "3. Double-check `unmirror_image()` and `unmirror_points()` are consistent with your capture scenario.\n",
    "   - The ChAruCo pattern detector ignores patterns captured through a mirror since it is flipped and is not valid as AruCo markers.\n",
    "   - `unmirror_image()` flips the ChAruCo pattern in captured image back to the original appearance, and allow the ChAruCo pattern detector find the chess corners.  `unmirror_points()` then flips the detected chess corner positions back to the original positions in the captured image.\n",
    "   - By default, these two functions flips left and right.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267dac32",
   "metadata": {},
   "source": [
    "## ChAruCo pattern\n",
    "\n",
    "This cell generates a ChAruCo pattern for your display, and saves it as `OUT_PATTERN`.\n",
    "\n",
    "It is strongly recommended to specify the exact resolution of your display in `DISPLAY_WIDTH` and `DISPLAY_HEIGHT`, and show the generated image in the fullscreen mode without any scaling.\n",
    "\n",
    "The cell also outputs the chess corner posisions in the pattern, and shows their detection order in the original pattern and its mirrored pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9560eada",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/mirror/GP12_5K_Wide.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Input images capturing the chessboard above\u001b[39;00m\n\u001b[1;32m     34\u001b[0m INPUT_FILES \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/mirror/frame_*.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 36\u001b[0m cameraMatrix, distCoeffs, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mpycalib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_calib\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/mirror/GP12_5K_Wide.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m cameraMatrix \u001b[38;5;241m=\u001b[39m cameraMatrix[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     38\u001b[0m distCoeffs \u001b[38;5;241m=\u001b[39m distCoeffs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/GitHub/pycalib/pycalib/util.py:52\u001b[0m, in \u001b[0;36mload_calib\u001b[0;34m(filename, check)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_calib\u001b[39m(filename, \u001b[38;5;241m*\u001b[39m, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mopen_z\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_yaml(filename):\n\u001b[1;32m     54\u001b[0m             J \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(fp)\n",
      "File \u001b[0;32m~/GitHub/pycalib/pycalib/util.py:100\u001b[0m, in \u001b[0;36mopen_z\u001b[0;34m(filename, mode)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bz2\u001b[38;5;241m.\u001b[39mopen(filename, mode)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/mirror/GP12_5K_Wide.json'"
     ]
    }
   ],
   "source": [
    "import sys, os, cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import pycalib\n",
    "\n",
    "\n",
    "# Chessboard configuration\n",
    "\n",
    "DISPLAY_WIDTH = 3840\n",
    "DISPLAY_HEIGHT = 2160\n",
    "BOARD_COLS = 18\n",
    "BOARD_ROWS = 10\n",
    "OUT_PATTERN = 'output-pattern.png'\n",
    "Np = (BOARD_COLS-1) * (BOARD_ROWS-1)\n",
    "\n",
    "aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_250)\n",
    "board = cv2.aruco.CharucoBoard((BOARD_COLS, BOARD_ROWS), 0.02, 0.015, aruco_dict)\n",
    "\n",
    "parameters =  cv2.aruco.DetectorParameters()\n",
    "parameters.cornerRefinementMethod = cv2.aruco.CORNER_REFINE_CONTOUR\n",
    "detector = cv2.aruco.CharucoDetector(board, detectorParams=parameters)\n",
    "\n",
    "# check if the board is correct\n",
    "image = board.generateImage((DISPLAY_WIDTH, DISPLAY_HEIGHT))\n",
    "cv2.imwrite(OUT_PATTERN, image)\n",
    "\n",
    "# Input images capturing the chessboard above\n",
    "INPUT_FILES = '../data/mirror/frame_*.jpg'\n",
    "\n",
    "cameraMatrix, distCoeffs, _, _, _ = pycalib.util.load_calib('../data/mirror/GP12_5K_Linear.json')\n",
    "cameraMatrix = cameraMatrix[0]\n",
    "distCoeffs = distCoeffs[0]\n",
    "\n",
    "# unmirror the captured image\n",
    "def unmirror_image(img):\n",
    "    return cv2.flip(img, 1)  # flip left-right\n",
    "\n",
    "# pts: Nx1x2\n",
    "def unmirror_points(sz, pts):\n",
    "    q = pts.copy()\n",
    "    q[:,0,0] = sz[1] - q[:,0,0] # flip left-right\n",
    "    return q\n",
    "\n",
    "def label_id(img, pts, *, radius=32, thickness=8):\n",
    "    pts = pts.reshape((-1, pts.shape[-1]))\n",
    "\n",
    "    img = img.copy()\n",
    "    if len(img.shape) == 2 or img.shape[2] == 1:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    for p in pts:\n",
    "        cv2.circle(img, (int(p[0]), int(p[1])), radius, (0,255,255), thickness)\n",
    "\n",
    "    for p, q in zip(pts, pts[1:]):\n",
    "        cv2.arrowedLine(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), (0,255,255), thickness)\n",
    "    return img\n",
    "\n",
    "# Detect the corners in the display image\n",
    "c_corners, c_ids, corners, ids = detector.detectBoard(image)\n",
    "objPoints, imgPoints = board.matchImagePoints(c_corners, c_ids)\n",
    "\n",
    "OBJ_PTS = np.rint(imgPoints).reshape((-1, 2))\n",
    "assert OBJ_PTS.shape == ((BOARD_COLS-1) * (BOARD_ROWS-1), 2)\n",
    "\n",
    "OBJ_PTS = np.concatenate([OBJ_PTS, np.zeros((len(OBJ_PTS), 1))], axis=1)\n",
    "print('Chess corners (x, y, z)')\n",
    "print(OBJ_PTS)\n",
    "\n",
    "\n",
    "\n",
    "# Display shows this pattern\n",
    "plt.figure()\n",
    "plt.imshow(label_id(image, OBJ_PTS))\n",
    "plt.title(f'Display image ({OUT_PATTERN})')\n",
    "#plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Camera captures this pattern (via mirror)\n",
    "plt.figure()\n",
    "plt.imshow(label_id(unmirror_image(image), unmirror_points(image.shape, OBJ_PTS[:,None,:])), cmap='gray')\n",
    "plt.title('Mirrored image')\n",
    "#plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "#print(objPoints, imgPoints, OBJ_PTS_PX)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfb7af8",
   "metadata": {},
   "source": [
    "## 2D corner detection\n",
    "\n",
    "This cell detects ChAruCo corners from images specified in `INPUT_FILES`.  Make sure that each image captures the pattern as shown in the \"Mirrored image\" above.\n",
    "\n",
    "- It is OK to have some corners missing (not detected) in some frames.  The algorithm utilizes images with at least 3 corners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de1250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PTS = []\n",
    "img_pts_nan = np.full((Np,2), np.nan)\n",
    "\n",
    "for idx, i in enumerate(sorted(glob(INPUT_FILES))):\n",
    "    frame = cv2.imread(i, cv2.IMREAD_COLOR)\n",
    "    frame = cv2.undistort(frame, cameraMatrix, distCoeffs)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = unmirror_image(gray) # mirror\n",
    "    c_corners, c_ids, corners, ids = detector.detectBoard(gray)\n",
    "    ret = len(c_corners) if c_corners is not None else 0\n",
    "    print(f'#{idx} {i}  found {ret} corners.')\n",
    "    if ret >= 3:\n",
    "        objPoints, imgPoints = board.matchImagePoints(c_corners, c_ids)\n",
    "        imgPoints = unmirror_points(gray.shape, imgPoints)\n",
    "        p = img_pts_nan.copy()\n",
    "        p[c_ids, :] = imgPoints\n",
    "        IMG_PTS.append(p)\n",
    "    else:\n",
    "        print(f'#{idx} {i}  too few points, ignored.')\n",
    "\n",
    "    imsize = (gray.shape[1], gray.shape[0])\n",
    "\n",
    "IMG_PTS = np.array(IMG_PTS)\n",
    "\n",
    "# show sample image\n",
    "plt.figure()\n",
    "plt.imshow(label_id(frame, imgPoints))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538d75ff",
   "metadata": {},
   "source": [
    "## Calibration\n",
    "\n",
    "This cell calibrates the camera and the mirror poses w.r.t. the ChAruCo pattern on the display.  It first computes a linear solution, and then fine-tune it to minimize the reprojection error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b052fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Camera Matrix', cameraMatrix)\n",
    "print('Object Points (Np x 3) = ', OBJ_PTS.shape)\n",
    "print('Image Points (Nm x Np x 2) = ', IMG_PTS.shape)\n",
    "print(f'{np.sum(np.isnan(IMG_PTS[:,:,0]))} out of {len(IMG_PTS.reshape((-1,2)))} points are masked out')\n",
    "\n",
    "R0, T0, n0, d0, rep0 = pycalib.mirror.tnm(OBJ_PTS, IMG_PTS, cameraMatrix)\n",
    "print(f'Reprojection error (linear) = {rep0:.3} px')\n",
    "\n",
    "R, T, n, d, rep = pycalib.mirror.tnm_ba(OBJ_PTS, IMG_PTS, cameraMatrix, R0, T0, n0, d0)\n",
    "print(f'Reprojection error (BA) = {rep:.3} px')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de84782e",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76088ac4-fa7a-434e-add5-40bc08f88495",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "display = np.array( [ [0, 0, 0],\n",
    "                      [DISPLAY_WIDTH, 0, 0],\n",
    "                      [DISPLAY_WIDTH, DISPLAY_HEIGHT, 0],\n",
    "                      [0, DISPLAY_HEIGHT, 0],\n",
    "                      [0, 0, 0] ] )\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "fig.add_axes(ax)\n",
    "\n",
    "# Display\n",
    "ax.scatter(OBJ_PTS[:,0], OBJ_PTS[:,1], OBJ_PTS[:,2])\n",
    "ax.plot(display[:,0], display[:,1], display[:,2])\n",
    "\n",
    "# World coordinate system\n",
    "ax.plot([0, DISPLAY_WIDTH], [0, 0], [0, 0], color='red')    # X\n",
    "ax.plot([0, 0], [0, DISPLAY_HEIGHT], [0, 0], color='green') # Y\n",
    "ax.plot([0, 0], [0, 0], [0, DISPLAY_HEIGHT], color='blue')  # Z\n",
    "\n",
    "# Camera\n",
    "pycalib.plot.plotCamera(ax, R.T, -R.T@T, scale=DISPLAY_WIDTH//8)\n",
    "\n",
    "# Mirror\n",
    "for i, (ni, di) in enumerate(zip(n, d)):\n",
    "    pycalib.plot.plotMirror(ax, display, ni, di, rf'$\\pi_{i}$')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
